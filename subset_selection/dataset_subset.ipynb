{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as pyplot\n",
    "import datetime\n",
    "import os, shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to use the original dataset (before cleaning) when finding the original distribution of values for the different parameters. This is because even though a taxi-trip is deleted during the cleaning, it doesn't mean that it is something wrong with the trip, just the GPS. So if for example a lot of the trips with a spesific value on one parameter is deleted (due to unlucky GPS): we still want the distribution to be the same in the subsets, to be as close as possible to reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('train.csv')\n",
    "cleaned_data = pd.read_csv('subset-5000-6-percent.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographical cleaning of original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set max and min coordinates for latitude and longitude\n",
    "MAX_LON = -8.45\n",
    "MIN_LON = -8.72\n",
    "MAX_LAT = 41.26\n",
    "MIN_LAT = 41.07\n",
    "\n",
    "# Will choose traces that are within a given rectangle of the city\n",
    "\n",
    "indexes_to_delete = []\n",
    "\n",
    "for index, row in original_data.iterrows():\n",
    "    trace_id = row[\"TRIP_ID\"] \n",
    "\n",
    "    trace = row[\"POLYLINE\"][2:-2].split(\"],[\")\n",
    "    if(trace[0]==''):\n",
    "        indexes_to_delete.append(index)\n",
    "    else:\n",
    "        # If trace are outside bounded rectangle: remove row\n",
    "        for coordinate in trace:\n",
    "            lon, lat = list(map(float, coordinate.split(\",\")))\n",
    "\n",
    "            # Outside bounded rectangle\n",
    "            if ( not ( MIN_LAT <= lat <= MAX_LAT )) or ( not ( MIN_LON <= lon <= MAX_LON )):\n",
    "                indexes_to_delete.append(index)\n",
    "                break\n",
    "      \n",
    "original_data.drop(indexes_to_delete, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some extra cleaning before the subset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_data = cleaned_data[cleaned_data['MISSING_DATA']!=True]\n",
    "#cleaned_data.drop(['ORIGIN_CALL', 'ORIGIN_STAND', 'TAXI_ID', 'MISSING_DATA', 'DAY_TYPE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1687289\n"
     ]
    }
   ],
   "source": [
    "original_length = len(original_data)\n",
    "subset_length = 2500\n",
    "#7500, 5000, 2500, 2000, 1500, 1000, 500, (300), 200, 100, 50\n",
    "print(original_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create subsets and check if they are good enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALL_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the distribution in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.485886531590022\n",
      "47.994386261037675\n",
      "30.5197272073723\n"
     ]
    }
   ],
   "source": [
    "#finding the number of rows of each call type (A, B, C) in the original dataset\n",
    "original_call_type_a_percentage = (len(original_data[original_data['CALL_TYPE']=='A'])/original_length)*100\n",
    "original_call_type_b_percentage = (len(original_data[original_data['CALL_TYPE']=='B'])/original_length)*100\n",
    "original_call_type_c_percentage = (len(original_data[original_data['CALL_TYPE']=='C'])/original_length)*100\n",
    "\n",
    "print(original_call_type_a_percentage)\n",
    "print(original_call_type_b_percentage)\n",
    "print(original_call_type_c_percentage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating method to check wheter a subset has a similar distribution as the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_type_accepted(subset_call_type_a_percentage, subset_call_type_b_percentage, subset_call_type_c_percentage):\n",
    "    if abs(original_call_type_a_percentage - subset_call_type_a_percentage) <= (original_call_type_a_percentage*0.06):\n",
    "        if abs(original_call_type_b_percentage - subset_call_type_b_percentage) <= (original_call_type_b_percentage*0.06):\n",
    "            if abs(original_call_type_c_percentage - subset_call_type_c_percentage) <= (original_call_type_c_percentage*0.06):\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIMESTAMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating method to get the info from (hours, weekdays and months) the timestamps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_from_timestamps(subset):\n",
    "    hours_dict = {\n",
    "        0:0,\n",
    "        1:0,\n",
    "        2:0,\n",
    "        3:0,\n",
    "        4:0,\n",
    "        5:0,\n",
    "        6:0,\n",
    "        7:0,\n",
    "        8:0,\n",
    "        9:0,\n",
    "        10:0,\n",
    "        11:0,\n",
    "        12:0,\n",
    "        13:0,\n",
    "        14:0,\n",
    "        15:0,\n",
    "        16:0,\n",
    "        17:0,\n",
    "        18:0,\n",
    "        19:0,\n",
    "        20:0,\n",
    "        21:0,\n",
    "        22:0,\n",
    "        23:0\n",
    "    }\n",
    "    days_dict={\n",
    "        \"Monday\":0,\n",
    "        \"Tuesday\":0,\n",
    "        \"Wednesday\":0,\n",
    "        \"Thursday\":0,\n",
    "        \"Friday\":0,\n",
    "        \"Saturday\":0,\n",
    "        \"Sunday\":0\n",
    "    }\n",
    "    months_dict={\n",
    "        1:0,\n",
    "        2:0,\n",
    "        3:0,\n",
    "        4:0,\n",
    "        5:0,\n",
    "        6:0,\n",
    "        7:0,\n",
    "        8:0,\n",
    "        9:0,\n",
    "        10:0,\n",
    "        11:0,\n",
    "        12:0\n",
    "    }\n",
    "    \n",
    "    for row in subset['TIMESTAMP']:\n",
    "        time = datetime.datetime.fromtimestamp(row)\n",
    "        hours_dict[time.hour]+=1\n",
    "        days_dict[time.strftime(\"%A\")]+=1\n",
    "        months_dict[time.month]+=1\n",
    "    return hours_dict, days_dict, months_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the timestamp-info from the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 49382, 1: 48950, 2: 49217, 3: 48666, 4: 46939, 5: 60166, 6: 55689, 7: 51901, 8: 53442, 9: 81162, 10: 97674, 11: 94085, 12: 87406, 13: 83077, 14: 81448, 15: 92886, 16: 89101, 17: 90799, 18: 85987, 19: 79722, 20: 73052, 21: 68931, 22: 62389, 23: 55218}\n",
      "{'Monday': 225943, 'Tuesday': 231870, 'Wednesday': 228455, 'Thursday': 242165, 'Friday': 268482, 'Saturday': 254860, 'Sunday': 235514}\n",
      "{1: 129300, 2: 128167, 3: 137245, 4: 134966, 5: 159705, 6: 151088, 7: 143410, 8: 123795, 9: 145514, 10: 151602, 11: 138232, 12: 144265}\n"
     ]
    }
   ],
   "source": [
    "#finding the number of rows of each hour, weekday and month from timestamp in the original dataset\n",
    "original_hours, original_weekdays, original_months = get_info_from_timestamps(original_data)\n",
    "\n",
    "print(original_hours)\n",
    "print(original_weekdays)\n",
    "print(original_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2.9267066874732186, 1: 2.9011034861247835, 2: 2.9169276869581915, 3: 2.8842717519049788, 4: 2.781918213181026, 5: 3.565838454467492, 6: 3.3005015738264163, 7: 3.075999428669303, 8: 3.1673293668126803, 9: 4.810201453337277, 10: 5.788812704877469, 11: 5.576104627008177, 12: 5.180262539493826, 13: 4.923697125981382, 14: 4.827151720896658, 15: 5.5050438899323115, 16: 5.280719544784563, 17: 5.381354350084663, 18: 5.096163135064591, 19: 4.724857448842492, 20: 4.329548761356235, 21: 4.085310815159703, 22: 3.697588261406315, 23: 3.272586972356247}\n",
      "{'Monday': 13.390889171920161, 'Tuesday': 13.742162723753903, 'Wednesday': 13.53976704642773, 'Thursday': 14.352313089221822, 'Friday': 15.912034038033793, 'Saturday': 15.10470346218105, 'Sunday': 13.958130468461539}\n",
      "{1: 7.6631804035941675, 2: 7.596031266724314, 3: 8.134054095060183, 4: 7.998985354613229, 5: 9.465183498499664, 6: 8.954482604936084, 7: 8.499433114303477, 8: 7.336917386410982, 9: 8.624130187537524, 10: 8.984945673207138, 11: 8.192550298140983, 12: 8.550106116972255}\n"
     ]
    }
   ],
   "source": [
    "#Convert original timestamps-dicts into percentage dicts\n",
    "original_hours_percentage_dict = {}\n",
    "for hour in original_hours:\n",
    "    original_hours_percentage_dict[hour] = (original_hours[hour]/original_length)*100\n",
    "\n",
    "original_weekdays_percentage_dict = {}\n",
    "for weekday in original_weekdays:\n",
    "    original_weekdays_percentage_dict[weekday] = (original_weekdays[weekday]/original_length)*100\n",
    "\n",
    "original_months_percentage_dict = {}\n",
    "for month in original_months:\n",
    "    original_months_percentage_dict[month] = (original_months[month]/original_length)*100\n",
    "\n",
    "print(original_hours_percentage_dict)\n",
    "print(original_weekdays_percentage_dict)\n",
    "print(original_months_percentage_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating functions for checking if hours, weekdays and months are evenly distributed compared to original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekdays_accepted(subset_weekdays_dict):\n",
    "    for weekday in subset_weekdays_dict:\n",
    "        subset_percentage = (subset_weekdays_dict[weekday]/subset_length)*100\n",
    "        if abs(original_weekdays_percentage_dict[weekday]-subset_percentage)>(original_weekdays_percentage_dict[weekday]*0.06):\n",
    "            return False\n",
    "    return True\n",
    "            \n",
    "def months_accepted(subset_months_dict):\n",
    "    for month in subset_months_dict:\n",
    "        subset_percentage = (subset_months_dict[month]/subset_length)*100\n",
    "        if abs(original_months_percentage_dict[month]-subset_percentage)>(original_months_percentage_dict[month]*0.06):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def hours_accepted(subset_hours_dict):\n",
    "    for hour in subset_hours_dict:\n",
    "        subset_percentage = (subset_hours_dict[hour]/subset_length)*100\n",
    "        if abs(original_hours_percentage_dict[hour]-subset_percentage)>(original_hours_percentage_dict[hour]*0.06):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods to print histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CALL_TYPE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_histogram(column, subset):\n",
    "    data_sorted = cleaned_data.sort_values(by=column)\n",
    "    subset_sorted = subset.sort_values(by=column)\n",
    "\n",
    "    pyplot.hist(data_sorted[column], bins='auto')\n",
    "    pyplot.xlabel(column)\n",
    "    pyplot.ylabel('number of rows')\n",
    "    pyplot.title('Original dataset. ' + column)\n",
    "    pyplot.show()\n",
    "\n",
    "    pyplot.hist(subset_sorted[column], bins='auto')\n",
    "    pyplot.xlabel(column)\n",
    "    pyplot.ylabel('number of rows')\n",
    "    pyplot.title('Subset, ' + column)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_histogram_timestamps(hours_dict, days_dict, months_dict):\n",
    "    keys_hours = list(hours_dict.keys())\n",
    "    values_hours = list(hours_dict.values())\n",
    "    pyplot.bar(keys_hours, values_hours)\n",
    "    pyplot.title(\"HOURS\")\n",
    "    pyplot.show()\n",
    "\n",
    "    keys_hours = list(original_hours.keys())\n",
    "    values_hours = list(original_hours.values())\n",
    "    pyplot.bar(keys_hours, values_hours)\n",
    "    pyplot.title(\"ORIGINAL HOURS\")\n",
    "    pyplot.show()\n",
    "\n",
    "    keys_days = list(days_dict.keys())\n",
    "    values_days = list(days_dict.values())\n",
    "    pyplot.bar(keys_days, values_days)\n",
    "    pyplot.title(\"DAYS\")\n",
    "    pyplot.show()\n",
    "\n",
    "    keys_days = list(original_weekdays.keys())\n",
    "    values_days = list(original_weekdays.values())\n",
    "    pyplot.bar(keys_days, values_days)\n",
    "    pyplot.title(\"ORIGINAL DAYS\")\n",
    "    pyplot.show()\n",
    "\n",
    "    keys_months = list(months_dict.keys())\n",
    "    values_months = list(months_dict.values())\n",
    "    pyplot.bar(keys_months, values_months)\n",
    "    pyplot.title(\"MONTHS\")\n",
    "    pyplot.show()\n",
    "\n",
    "    keys_months = list(original_months.keys())\n",
    "    values_months = list(original_months.values())\n",
    "    pyplot.bar(keys_months, values_months)\n",
    "    pyplot.title(\"ORIGINAL MONTHS\")\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create subset\n",
    "Chose a random subset of the chosen size (subset_length), and check if the distribution is similar enough. Try again until a solution is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_ok = False\n",
    "counter = 1\n",
    "\n",
    "while subset_ok==False:\n",
    "    #create subset, from the cleaned data\n",
    "    subset = cleaned_data.sample(n=subset_length)\n",
    "\n",
    "    #CALL_TYPE\n",
    "    subset_call_type_a_percentage = (len(subset[subset['CALL_TYPE']=='A'])/subset_length)*100\n",
    "    subset_call_type_b_percentage = (len(subset[subset['CALL_TYPE']=='B'])/subset_length)*100\n",
    "    subset_call_type_c_percentage = (len(subset[subset['CALL_TYPE']=='C'])/subset_length)*100\n",
    "\n",
    "    #HOURS; WEEKDAYS; MONTHS\n",
    "    subset_hours_dict, subset_weekdays_dict, subset_months_dict = get_info_from_timestamps(subset)\n",
    "\n",
    "    if months_accepted(subset_months_dict):\n",
    "        if hours_accepted(subset_hours_dict):\n",
    "            if weekdays_accepted(subset_weekdays_dict):\n",
    "                if call_type_accepted(subset_call_type_a_percentage, subset_call_type_b_percentage, subset_call_type_c_percentage):\n",
    "                    print(counter)\n",
    "                    subset_ok=True\n",
    "                    subset.to_csv('subset-2500-6-percent.csv', index=False)\n",
    "                    print_histogram(\"CALL_TYPE\", subset)\n",
    "                    print_histogram_timestamps(subset_hours_dict, subset_weekdays_dict, subset_months_dict)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "input_file = \"subset-2500-6-percent.csv\"\n",
    "output_file = \"sorted-subset-2500-6.csv\"\n",
    "\n",
    "\n",
    "# Read the CSV file into a list of dictionaries\n",
    "with open(input_file, 'r') as csv_input:\n",
    "    reader = csv.DictReader(csv_input)\n",
    "    data = [row for row in reader]\n",
    "\n",
    "# Sort the data based on the 'INDEX' field\n",
    "sorted_data = sorted(data, key=lambda x: int(x['INDEX']))\n",
    "\n",
    "# Write the sorted data to a new CSV file\n",
    "with open(output_file, 'w', newline='') as csv_output:\n",
    "    fieldnames = reader.fieldnames\n",
    "    writer = csv.DictWriter(csv_output, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(sorted_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
