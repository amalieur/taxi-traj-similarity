{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as pyplot\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to use the original dataset (before cleaning) when finding the original distribution of values for the different parameters. This is because even though a taxi-trip is deleted during the cleaning, it doesn't mean that it is something wrong with the trip, just the GPS. So if for example a lot of the trips with a spesific value on one parameter is deleted (due to unlucky GPS): we still want the distribution to be the same in the subsets, to be as close as possible to reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('train.csv')\n",
    "cleaned_data = pd.read_csv('../dataset/chosen_geographical_area_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographical cleaning of original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "#Set max and min coordinates for latitude and longitude\n",
    "MAX_LON = -8.45\n",
    "MIN_LON = -8.72\n",
    "MAX_LAT = 41.26\n",
    "MIN_LAT = 41.07\n",
    "\n",
    "# This cell will read the data and generate a file for each trajectory in the given output directory\n",
    "# Will choose traces that are within a given rectangle of the city\n",
    "\n",
    "indexes_to_delete = []\n",
    "\n",
    "for index, row in original_data.iterrows():\n",
    "    trace_id = row[\"TRIP_ID\"] \n",
    "\n",
    "    trace = row[\"POLYLINE\"][2:-2].split(\"],[\")\n",
    "    if(trace[0]==''):\n",
    "        indexes_to_delete.append(index)\n",
    "    else:\n",
    "        # If trace are outside bounded rectangle: remove row\n",
    "        for coordinate in trace:\n",
    "            lon, lat = list(map(float, coordinate.split(\",\")))\n",
    "\n",
    "            # Outside bounded rectangle\n",
    "            if ( not ( MIN_LAT <= lat <= MAX_LAT )) or ( not ( MIN_LON <= lon <= MAX_LON )):\n",
    "                indexes_to_delete.append(index)\n",
    "                break\n",
    "      \n",
    "original_data.drop(indexes_to_delete, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some extra cleaning before the subset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>POLYLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>C</td>\n",
       "      <td>1372636858</td>\n",
       "      <td>[[-8.618643,41.141412],[-8.618499,41.141376],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1372637303620000596</td>\n",
       "      <td>B</td>\n",
       "      <td>1372637303</td>\n",
       "      <td>[[-8.639847,41.159826],[-8.640351,41.159871],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1372637091620000337</td>\n",
       "      <td>C</td>\n",
       "      <td>1372637091</td>\n",
       "      <td>[[-8.645994,41.18049],[-8.645949,41.180517],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1372636965620000231</td>\n",
       "      <td>C</td>\n",
       "      <td>1372636965</td>\n",
       "      <td>[[-8.615502,41.140674],[-8.614854,41.140926],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1372637210620000456</td>\n",
       "      <td>C</td>\n",
       "      <td>1372637210</td>\n",
       "      <td>[[-8.57952,41.145948],[-8.580942,41.145039],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1372637299620000011</td>\n",
       "      <td>C</td>\n",
       "      <td>1372637299</td>\n",
       "      <td>[[-8.617563,41.146182],[-8.617527,41.145849],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1372637274620000403</td>\n",
       "      <td>C</td>\n",
       "      <td>1372637274</td>\n",
       "      <td>[[-8.611794,41.140557],[-8.611785,41.140575],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1372637905620000320</td>\n",
       "      <td>C</td>\n",
       "      <td>1372637905</td>\n",
       "      <td>[[-8.615907,41.140557],[-8.614449,41.141088],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1372636875620000233</td>\n",
       "      <td>C</td>\n",
       "      <td>1372636875</td>\n",
       "      <td>[[-8.619894,41.148009],[-8.620164,41.14773],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1372637984620000520</td>\n",
       "      <td>C</td>\n",
       "      <td>1372637984</td>\n",
       "      <td>[[-8.56242,41.168403],[-8.562429,41.168358],[-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TRIP_ID CALL_TYPE   TIMESTAMP  \\\n",
       "0  1372636858620000589         C  1372636858   \n",
       "1  1372637303620000596         B  1372637303   \n",
       "2  1372637091620000337         C  1372637091   \n",
       "3  1372636965620000231         C  1372636965   \n",
       "4  1372637210620000456         C  1372637210   \n",
       "5  1372637299620000011         C  1372637299   \n",
       "6  1372637274620000403         C  1372637274   \n",
       "7  1372637905620000320         C  1372637905   \n",
       "8  1372636875620000233         C  1372636875   \n",
       "9  1372637984620000520         C  1372637984   \n",
       "\n",
       "                                            POLYLINE  \n",
       "0  [[-8.618643,41.141412],[-8.618499,41.141376],[...  \n",
       "1  [[-8.639847,41.159826],[-8.640351,41.159871],[...  \n",
       "2  [[-8.645994,41.18049],[-8.645949,41.180517],[-...  \n",
       "3  [[-8.615502,41.140674],[-8.614854,41.140926],[...  \n",
       "4  [[-8.57952,41.145948],[-8.580942,41.145039],[-...  \n",
       "5  [[-8.617563,41.146182],[-8.617527,41.145849],[...  \n",
       "6  [[-8.611794,41.140557],[-8.611785,41.140575],[...  \n",
       "7  [[-8.615907,41.140557],[-8.614449,41.141088],[...  \n",
       "8  [[-8.619894,41.148009],[-8.620164,41.14773],[-...  \n",
       "9  [[-8.56242,41.168403],[-8.562429,41.168358],[-...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = cleaned_data[cleaned_data['MISSING_DATA']!=True]\n",
    "cleaned_data.drop(['ORIGIN_CALL', 'ORIGIN_STAND', 'TAXI_ID', 'MISSING_DATA', 'DAY_TYPE'], axis=1, inplace=True)\n",
    "cleaned_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1687289\n"
     ]
    }
   ],
   "source": [
    "original_length = len(original_data)\n",
    "subset_length = 100000\n",
    "#7500, 5000, 2500, 2000, 1500, 1000, 500, (300), 200, 100, 50\n",
    "print(original_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create subsets and check if they are good enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALL_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the distribution in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.485886531590022\n",
      "47.994386261037675\n",
      "30.5197272073723\n"
     ]
    }
   ],
   "source": [
    "#finding the number of rows of each call type (A, B, C) in the original dataset\n",
    "original_call_type_a_percentage = (len(original_data[original_data['CALL_TYPE']=='A'])/original_length)*100\n",
    "original_call_type_b_percentage = (len(original_data[original_data['CALL_TYPE']=='B'])/original_length)*100\n",
    "original_call_type_c_percentage = (len(original_data[original_data['CALL_TYPE']=='C'])/original_length)*100\n",
    "\n",
    "print(original_call_type_a_percentage)\n",
    "print(original_call_type_b_percentage)\n",
    "print(original_call_type_c_percentage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating method to check wheter a subset has a similar distribution as the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_type_accepted(subset_call_type_a_percentage, subset_call_type_b_percentage, subset_call_type_c_percentage):\n",
    "    if abs(original_call_type_a_percentage - subset_call_type_a_percentage) <= (original_call_type_a_percentage*0.05):\n",
    "        if abs(original_call_type_b_percentage - subset_call_type_b_percentage) <= (original_call_type_b_percentage*0.05):\n",
    "            if abs(original_call_type_c_percentage - subset_call_type_c_percentage) <= (original_call_type_c_percentage*0.05):\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIMESTAMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating method to get the info from (hours, weekdays and months) the timestamps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_from_timestamps(subset):\n",
    "    hours_dict = {\n",
    "        0:0,\n",
    "        1:0,\n",
    "        2:0,\n",
    "        3:0,\n",
    "        4:0,\n",
    "        5:0,\n",
    "        6:0,\n",
    "        7:0,\n",
    "        8:0,\n",
    "        9:0,\n",
    "        10:0,\n",
    "        11:0,\n",
    "        12:0,\n",
    "        13:0,\n",
    "        14:0,\n",
    "        15:0,\n",
    "        16:0,\n",
    "        17:0,\n",
    "        18:0,\n",
    "        19:0,\n",
    "        20:0,\n",
    "        21:0,\n",
    "        22:0,\n",
    "        23:0\n",
    "    }\n",
    "    days_dict={\n",
    "        \"Monday\":0,\n",
    "        \"Tuesday\":0,\n",
    "        \"Wednesday\":0,\n",
    "        \"Thursday\":0,\n",
    "        \"Friday\":0,\n",
    "        \"Saturday\":0,\n",
    "        \"Sunday\":0\n",
    "    }\n",
    "    months_dict={\n",
    "        1:0,\n",
    "        2:0,\n",
    "        3:0,\n",
    "        4:0,\n",
    "        5:0,\n",
    "        6:0,\n",
    "        7:0,\n",
    "        8:0,\n",
    "        9:0,\n",
    "        10:0,\n",
    "        11:0,\n",
    "        12:0\n",
    "    }\n",
    "    \n",
    "    for row in subset['TIMESTAMP']:\n",
    "        time = datetime.datetime.fromtimestamp(row)\n",
    "        hours_dict[time.hour]+=1\n",
    "        days_dict[time.strftime(\"%A\")]+=1\n",
    "        months_dict[time.month]+=1\n",
    "    return hours_dict, days_dict, months_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the timestamp-info from the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 49382, 1: 48950, 2: 49217, 3: 48666, 4: 46939, 5: 60166, 6: 55689, 7: 51901, 8: 53442, 9: 81162, 10: 97674, 11: 94085, 12: 87406, 13: 83077, 14: 81448, 15: 92886, 16: 89101, 17: 90799, 18: 85987, 19: 79722, 20: 73052, 21: 68931, 22: 62389, 23: 55218}\n",
      "{'Monday': 225943, 'Tuesday': 231870, 'Wednesday': 228455, 'Thursday': 242165, 'Friday': 268482, 'Saturday': 254860, 'Sunday': 235514}\n",
      "{1: 129300, 2: 128167, 3: 137245, 4: 134966, 5: 159705, 6: 151088, 7: 143410, 8: 123795, 9: 145514, 10: 151602, 11: 138232, 12: 144265}\n"
     ]
    }
   ],
   "source": [
    "#finding the number of rows of each hour, weekday and month from timestamp in the original dataset\n",
    "original_hours, original_weekdays, original_months = get_info_from_timestamps(original_data)\n",
    "\n",
    "print(original_hours)\n",
    "print(original_weekdays)\n",
    "print(original_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2.9267066874732186, 1: 2.9011034861247835, 2: 2.9169276869581915, 3: 2.8842717519049788, 4: 2.781918213181026, 5: 3.565838454467492, 6: 3.3005015738264163, 7: 3.075999428669303, 8: 3.1673293668126803, 9: 4.810201453337277, 10: 5.788812704877469, 11: 5.576104627008177, 12: 5.180262539493826, 13: 4.923697125981382, 14: 4.827151720896658, 15: 5.5050438899323115, 16: 5.280719544784563, 17: 5.381354350084663, 18: 5.096163135064591, 19: 4.724857448842492, 20: 4.329548761356235, 21: 4.085310815159703, 22: 3.697588261406315, 23: 3.272586972356247}\n",
      "{'Monday': 13.390889171920161, 'Tuesday': 13.742162723753903, 'Wednesday': 13.53976704642773, 'Thursday': 14.352313089221822, 'Friday': 15.912034038033793, 'Saturday': 15.10470346218105, 'Sunday': 13.958130468461539}\n",
      "{1: 7.6631804035941675, 2: 7.596031266724314, 3: 8.134054095060183, 4: 7.998985354613229, 5: 9.465183498499664, 6: 8.954482604936084, 7: 8.499433114303477, 8: 7.336917386410982, 9: 8.624130187537524, 10: 8.984945673207138, 11: 8.192550298140983, 12: 8.550106116972255}\n"
     ]
    }
   ],
   "source": [
    "#Convert original timestamps-dicts into percentage dicts\n",
    "original_hours_percentage_dict = {}\n",
    "for hour in original_hours:\n",
    "    original_hours_percentage_dict[hour] = (original_hours[hour]/original_length)*100\n",
    "\n",
    "original_weekdays_percentage_dict = {}\n",
    "for weekday in original_weekdays:\n",
    "    original_weekdays_percentage_dict[weekday] = (original_weekdays[weekday]/original_length)*100\n",
    "\n",
    "original_months_percentage_dict = {}\n",
    "for month in original_months:\n",
    "    original_months_percentage_dict[month] = (original_months[month]/original_length)*100\n",
    "\n",
    "print(original_hours_percentage_dict)\n",
    "print(original_weekdays_percentage_dict)\n",
    "print(original_months_percentage_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating functions for checking if hours, weekdays and months are evenly distributed compared to original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekdays_accepted(subset_weekdays_dict):\n",
    "    for weekday in subset_weekdays_dict:\n",
    "        subset_percentage = (subset_weekdays_dict[weekday]/subset_length)*100\n",
    "        if abs(original_weekdays_percentage_dict[weekday]-subset_percentage)>(original_weekdays_percentage_dict[weekday]*0.05):\n",
    "            return False\n",
    "    return True\n",
    "            \n",
    "def months_accepted(subset_months_dict):\n",
    "    for month in subset_months_dict:\n",
    "        subset_percentage = (subset_months_dict[month]/subset_length)*100\n",
    "        if abs(original_months_percentage_dict[month]-subset_percentage)>(original_months_percentage_dict[month]*0.05):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def hours_accepted(subset_hours_dict):\n",
    "    for hour in subset_hours_dict:\n",
    "        subset_percentage = (subset_hours_dict[hour]/subset_length)*100\n",
    "        if abs(original_hours_percentage_dict[hour]-subset_percentage)>(original_hours_percentage_dict[hour]*0.05):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods to print histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CALL_TYPE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_histogram(column, subset):\n",
    "    data_sorted = cleaned_data.sort_values(by=column)\n",
    "    subset_sorted = subset.sort_values(by=column)\n",
    "\n",
    "    pyplot.hist(data_sorted[column], bins='auto')\n",
    "    pyplot.xlabel(column)\n",
    "    pyplot.ylabel('number of rows')\n",
    "    pyplot.title('Original dataset. ' + column)\n",
    "    pyplot.show()\n",
    "\n",
    "    pyplot.hist(subset_sorted[column], bins='auto')\n",
    "    pyplot.xlabel(column)\n",
    "    pyplot.ylabel('number of rows')\n",
    "    pyplot.title('Subset, ' + column)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_histogram_timestamps(hours_dict, days_dict, months_dict):\n",
    "    keys_hours = list(hours_dict.keys())\n",
    "    values_hours = list(hours_dict.values())\n",
    "    pyplot.bar(keys_hours, values_hours)\n",
    "    pyplot.title(\"HOURS\")\n",
    "    pyplot.show()\n",
    "\n",
    "    keys_hours = list(original_hours.keys())\n",
    "    values_hours = list(original_hours.values())\n",
    "    pyplot.bar(keys_hours, values_hours)\n",
    "    pyplot.title(\"ORIGINAL HOURS\")\n",
    "    pyplot.show()\n",
    "\n",
    "    keys_days = list(days_dict.keys())\n",
    "    values_days = list(days_dict.values())\n",
    "    pyplot.bar(keys_days, values_days)\n",
    "    pyplot.title(\"DAYS\")\n",
    "    pyplot.show()\n",
    "\n",
    "    keys_days = list(original_weekdays.keys())\n",
    "    values_days = list(original_weekdays.values())\n",
    "    pyplot.bar(keys_days, values_days)\n",
    "    pyplot.title(\"ORIGINAL DAYS\")\n",
    "    pyplot.show()\n",
    "\n",
    "    keys_months = list(months_dict.keys())\n",
    "    values_months = list(months_dict.values())\n",
    "    pyplot.bar(keys_months, values_months)\n",
    "    pyplot.title(\"MONTHS\")\n",
    "    pyplot.show()\n",
    "\n",
    "    keys_months = list(original_months.keys())\n",
    "    values_months = list(original_months.values())\n",
    "    pyplot.bar(keys_months, values_months)\n",
    "    pyplot.title(\"ORIGINAL MONTHS\")\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create subset\n",
    "Chose a random subset of the chosen size (subset_length), and check if the distribution is similar enough. Try again until a solution is found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_ok = False\n",
    "counter = 1\n",
    "\n",
    "while subset_ok==False:\n",
    "    #create subset, from the cleaned data\n",
    "    subset = cleaned_data.sample(n=subset_length)\n",
    "\n",
    "    #CALL_TYPE\n",
    "    subset_call_type_a_percentage = (len(subset[subset['CALL_TYPE']=='A'])/subset_length)*100\n",
    "    subset_call_type_b_percentage = (len(subset[subset['CALL_TYPE']=='B'])/subset_length)*100\n",
    "    subset_call_type_c_percentage = (len(subset[subset['CALL_TYPE']=='C'])/subset_length)*100\n",
    "\n",
    "    #HOURS; WEEKDAYS; MONTHS\n",
    "    subset_hours_dict, subset_weekdays_dict, subset_months_dict = get_info_from_timestamps(subset)\n",
    "\n",
    "    if months_accepted(subset_months_dict):\n",
    "        if hours_accepted(subset_hours_dict):\n",
    "            if weekdays_accepted(subset_weekdays_dict):\n",
    "                if call_type_accepted(subset_call_type_a_percentage, subset_call_type_b_percentage, subset_call_type_c_percentage):\n",
    "                    print(counter)\n",
    "                    subset_ok=True\n",
    "                    subset.to_csv('subset-100000-5-percent.csv', index=False)\n",
    "                    print_histogram(\"CALL_TYPE\", subset)\n",
    "                    print_histogram_timestamps(subset_hours_dict, subset_weekdays_dict, subset_months_dict)\n",
    "    counter+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
